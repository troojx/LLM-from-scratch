{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5212f966",
   "metadata": {},
   "source": [
    "# Chapter 7: Finetuning To Follow Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a12c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1+cu121\n",
      "tqdm version: 4.66.6\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",  # Plotting library 画图的\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2cd12",
   "metadata": {},
   "source": [
    "## 7.1 指令微调简介\n",
    "- 在第5章中，我们看到，对LLM（大语言模型）的预训练涉及一种逐字生成的训练过程。\n",
    "- 因此，预训练的LLM擅长文本补全，但并不擅长遵循指令。\n",
    "- 在本章中，我们将教会LLM更好地遵循指令。\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/instruction-following.webp\" width=500px>\n",
    "- 下面是本章的主题\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-1.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5551f",
   "metadata": {},
   "source": [
    "## 7.2 准备用于监督指令微调的数据集\n",
    "- 我们将使用为本章准备的一个指令数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebbc0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933df3e2",
   "metadata": {},
   "source": [
    "- 从上方的JSON文件加载的数据列表中的每个条目都是以下形式的字典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0d6bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af667fac",
   "metadata": {},
   "source": [
    "- 请注意，input字段可以为空："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6c2732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8256a5b",
   "metadata": {},
   "source": [
    "- 指令微调通常被称为“监督指令微调”supervised instruction finetuning，因为它涉及对一个显式提供输入-输出对的数据集进行训练。\n",
    "- 将这些条目格式化为LLM的输入有多种方式；下图展示了用于训练Alpaca(https://crfm.stanford.edu/2023/03/13/alpaca.html)和Phi-3(https://arxiv.org/abs/2404.14219) LLM的两个示例格式。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/prompt-style.webp?1\" width=500px>\n",
    "- 这章我们用Alpaca-style prompt formatting，它是original prompt template for instruction finetuning\n",
    "- 下面格式化我们给LLM传入的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4975173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f12478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "#A formatted response with input field\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "972b8ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "#formatted response without an input field\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae384b23",
   "metadata": {},
   "source": [
    "- 最后，在下一节准备PyTorch数据加载器之前，我们将数据集分为训练集、验证集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d19c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "184a501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dadd8a",
   "metadata": {},
   "source": [
    "## 7.3 将数据组织为训练批次\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-2.webp?1\" width=500px>\n",
    "- 我们通过以下几个步骤处理数据集批处理，如下图所示：\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/detailed-batching.webp?1\" width=500px>\n",
    "- 首先，我们实现了一个 `InstructionDataset`类，用于对数据集中的所有输入进行预处理，类似于第6章中的`SpamDataset`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a554dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a81c6",
   "metadata": {},
   "source": [
    "- 与第6章类似，我们希望在一个批次中收集多个训练样本以加速训练；这需要将所有输入填充到相似的长度。\n",
    "- 同样类似于上一章，我们使用<|endoftext|>作为填充标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce447792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbf8334",
   "metadata": {},
   "source": [
    "- 在第6章中，我们将数据集中所有样本填充到相同长度。\n",
    "    - 在这里，我们采用了一种更复杂的方法，开发了一个自定义的“collate”函数，可以传递给数据加载器。\n",
    "    - 这个自定义collate函数将每个批次中的训练样本填充到相同长度（但不同批次可以具有不同长度）。\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/padding.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4750c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    #找到批次中最长的序列长度，并额外加 1,是为了在每个序列末尾添加一个 <|endoftext|> 标记。\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs 创建空列表用于存储填充后的序列\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        #在当前序列的末尾 Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token移除多余的填充标记\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1]) #去掉最后一个多余的填充标记\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f1819f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc83df0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-4.webp?1\" width=500px>\n",
    "\n",
    "\n",
    "- 在上面，我们只返回了LLM的输入；然而，对于LLM的训练，我们还需要target values\n",
    "- 类似于LLM的预训练，目标是将输入向右移动1个位置，这样LLM就可以学习预测下一个标记。\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/inputs-targets.webp?1\" width=400px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f52713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7862c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809556a5",
   "metadata": {},
   "source": [
    "- 接下来，我们引入一个ignore_index值，用于将所有填充标记ID替换为一个新值；ignore_index的目的是在损失函数中忽略填充值（稍后会详细讨论）。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-5.webp?1\" width=500px>\n",
    "\n",
    "- 具体来说，这意味着我们将对应于50256的标记ID替换为-100，但是第一个不会换，如下所示：\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ignore-index.webp?1\" width=500px>\n",
    "\n",
    "- （此外，我们还引入了allowed_max_length，以防我们想限制样本长度；这对于您计划使用自己超过GPT-2模型支持的1024标记上下文大小的数据集时非常有用）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f233a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        #除了第一个都替换\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()  \n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length  \n",
    "        # 如果限定了最大长度就截断\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ccd4580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae03894",
   "metadata": {},
   "source": [
    "- 让我们看看将50256替换为-100的作用。\n",
    "- 为了说明，假设我们有一个小型分类任务，具有两个类别标签0和1，类似于第6章。\n",
    "- 如果我们有以下logits值（模型最后一层的输出），我们计算如下损失："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8187808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81b601",
   "metadata": {},
   "source": [
    "- 现在加入一个训练例子，会影响loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "599f6c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c7ede",
   "metadata": {},
   "source": [
    "- 看看如果把所有 分类标签为1的样例换成-100 会发生什么\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7be91152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aebddf",
   "metadata": {},
   "source": [
    "- 可以看到，这3个训练样本的最终损失与我们从2个训练样本计算的损失相同，这意味着交叉熵损失函数忽略了带有标签-100的训练样本。\n",
    "- 默认情况下，PyTorch的cross_entropy(..., ignore_index=-100)设置会忽略标签为-100的样本。\n",
    "\n",
    "- 使用这个-100的ignore_index，我们可以忽略用于填充训练样本以达到相同长度的额外文本结束标记（padding token）。\n",
    "- 然而，我们不希望忽略第一个文本结束标记（50256）的实例，因为它可以帮助向LLM指示响应何时完成。\n",
    "- 在实践中，通常也会屏蔽与指令对应的目标标记ID，如下图所示（这是一个推荐的读者练习，建议在完成本章后尝试）。\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/mask-instructions.webp?1\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b765cdc",
   "metadata": {},
   "source": [
    "## 7.4 为instruction dataset创建data loaders\n",
    "- 在本节中，我们将使用 InstructionDataset 类和 custom_collate_fn 函数来实例化训练集、验证集和测试集的数据加载器。\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-3.webp?1\" width=500px>\n",
    "- 上述 custom_collate_fn 函数的另一个改进是：我们现在直接将数据移动到目标设备（例如 GPU），而不是在主训练循环中完成这一步操作。\n",
    "- 这样可以提高效率，因为在将 custom_collate_fn 作为数据加载器的一部分时，这一步可以作为后台进程执行。\n",
    "- 使用 Python 的 functools 标准库中的 partial 函数，我们创建了一个新的函数，将原函数的 device 参数预先填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dffcfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b03de759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7dc166",
   "metadata": {},
   "source": [
    "- 接下来，我们与前几章类似地实例化数据加载器，不同之处在于我们现在为批处理过程提供了自定义的 collate 函数。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0ec76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123) #可复现性\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6db73922",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    #collate函数将每个批次中的训练样本填充到相同长度（但不同批次可以具有不同长度）\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e404d",
   "metadata": {},
   "source": [
    "- 让我们看一下生成的输入和目标批次的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "404921be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4646e36",
   "metadata": {},
   "source": [
    "- 从上面的输出可以看到，所有批次的大小都是 8，但长度不同，这与预期一致。\n",
    "\n",
    "- 我们还可以通过打印输入批次中第一个训练样本的内容，仔细检查它是否包含 <|endoftext|> 填充值（对应 token ID 为 50256）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1e0d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a2b2d",
   "metadata": {},
   "source": [
    "- 同样，我们可以通过打印目标数据中的内容，确认是否包含 -100 占位符 token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "996172a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebae13",
   "metadata": {},
   "source": [
    "## 7.5 加载预训练 LLM\n",
    "- 在本节中，我们将使用第 5.5 节和第 6.4 节中的代码加载一个预训练的 GPT 模型。\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-4.webp?1\" width=500px>\n",
    "- 不过，这次我们不是加载最小的 124M 参数模型，而是加载中等版本的 355M 参数模型，因为 124M 的模型太小，无法通过指令微调获得合理的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b07e133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a49cd",
   "metadata": {},
   "source": [
    "- 在下一节开始微调模型之前，我们可以先看一下它在验证任务中的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff8123ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80f30ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d64fc",
   "metadata": {},
   "source": [
    "- 需要注意的是，我们在之前章节中使用的 generate 函数会返回合并后的输入和输出文本，这在上一节中方便了可读文本的创建。\n",
    "- 为了提取单独的响应部分，我们可以从生成的 generated_text 中减去指令的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a716c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d331d3",
   "metadata": {},
   "source": [
    "- 从结果可以看出，模型还不具备遵循指令的能力；它虽然生成了一个“Response”部分，但只是简单地重复了原始输入句子以及指令。\n",
    "\n",
    "## 7.6 在指令数据上微调 LLM\n",
    "- 在本节中，我们对模型进行微调。\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-5.webp?1\" width=500px>\n",
    "- 需要注意的是，我们可以重用之前章节中用来计算损失和进行训练的所有函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b45c0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc467f58",
   "metadata": {},
   "source": [
    "- 在开始训练之前，让我们先计算训练集和验证集的初始损失（与之前章节一样，我们的目标是最小化损失）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81515331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.82590970993042\n",
      "Validation loss: 3.761934280395508\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f34d2",
   "metadata": {},
   "source": [
    "- 由于我们使用了更大的模型（355M 参数，而不是 124M 参数），训练成本比之前的章节更高。\n",
    "- 以下是各种设备的运行时间参考（如果在兼容的 GPU 设备上运行此笔记本，无需更改代码）。\n",
    "| Model              | Device                | Runtime for 2 Epochs |\n",
    "|--------------------|-----------------------|----------------------|\n",
    "| gpt2-medium (355M) | CPU (M3 MacBook Air)  | 15.78 minutes        |\n",
    "| gpt2-medium (355M) | GPU (M3 MacBook Air)  | 10.77 minutes        |\n",
    "| gpt2-medium (355M) | GPU (L4)              | 1.83 minutes         |\n",
    "| gpt2-medium (355M) | GPU (A100)            | 0.86 minutes         |\n",
    "| gpt2-small (124M)  | CPU (M3 MacBook Air)  | 5.74 minutes         |\n",
    "| gpt2-small (124M)  | GPU (M3 MacBook Air)  | 3.73 minutes         |\n",
    "| gpt2-small (124M)  | GPU (L4)              | 0.69 minutes         |\n",
    "| gpt2-small (124M)  | GPU (A100)            | 0.39 minutes         |\n",
    "\n",
    "\n",
    "- 我使用了“gpt2-medium (355M)”模型运行了此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc439517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.728\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
      "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.676\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.666\n",
      "Ep 1 (Step 000115): Train loss 0.507, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.687\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.683\n",
      "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.682\n",
      "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.680\n",
      "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.680\n",
      "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.412, Val loss 0.675\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.684\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.687\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.682\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.670\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.657\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.658\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.649\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.635\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.635\n",
      "Ep 2 (Step 000205): Train loss 0.352, Val loss 0.632\n",
      "Ep 2 (Step 000210): Train loss 0.366, Val loss 0.631\n",
      "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.634\n",
      "Ep 2 (Step 000220): Train loss 0.299, Val loss 0.646\n",
      "Ep 2 (Step 000225): Train loss 0.345, Val loss 0.659\n",
      "Ep 2 (Step 000230): Train loss 0.291, Val loss 0.660\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 3.70 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79796d3",
   "metadata": {},
   "source": [
    "- 从上述输出可以看出，模型训练效果良好，从减少的训练损失和验证损失值可以看出来。\n",
    "\n",
    "- 此外，从每个 epoch 结束后打印的响应文本可以看出，模型能够正确遵循指令，例如将输入句子“厨师每天做饭”（The chef cooks the meal every day.）转换为被动语态“这顿饭每天由厨师烹饪”（The meal is cooked every day by the chef.）。（我们将在后面的章节中正式格式化并评估这些响应。）\n",
    "- 最后，让我们看一下训练和验证损失曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a693303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639766a8",
   "metadata": {},
   "source": [
    "- 从曲线可以看出，第一轮训练 epoch 的开始阶段损失急剧下降，这意味着模型开始快速学习。\n",
    "- 我们可以看到，经过大约 1 个训练 epoch 后，出现了轻微的过拟合。\n",
    "## 7.7 Extracting and saving responses\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-6.webp?1\" width=500px>\n",
    "- 在本节中，我们将保存测试集的响应，以便在下一节进行评分，同时保存一份模型的副本以供将来使用。\n",
    "- 但首先，让我们简要查看一下微调模型生成的响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cab8160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4c162",
   "metadata": {},
   "source": [
    "- 正如我们从测试集的指令、给定的响应以及模型的响应中可以看到的，模型的表现相对较好。\n",
    "\n",
    "- 对于第一条和最后一条指令，模型的回答显然是正确的。\n",
    "\n",
    "- 第二个答案也很接近；模型给出的答案是“积云”而不是“雷雨云”（不过需要注意的是，积云可以发展成雷雨云，而雷雨云能够产生雷暴）。\n",
    "\n",
    "- 最重要的是，我们可以看到，模型的评估并不像上一章那样简单，只需计算正确的垃圾邮件/非垃圾邮件标签的百分比来获得分类准确率。\n",
    "\n",
    "- 在实际应用中，指令微调的LLM（如聊天机器人）通常通过多种方法进行评估：\n",
    "\n",
    "    - 短答案和多选基准，如MMLU（“衡量大规模多任务语言理解”，测试模型的知识（https://arxiv.org/abs/2009.03300 ）；\n",
    "    - 与其他LLM的人工偏好比较，如LMSYS聊天机器人竞技场（https://arena.lmsys.org ）；\n",
    "    - 自动化对话基准，其中使用另一个LLM（如GPT-4）来评估响应，如AlpacaEval（https://tatsu-lab.github.io/alpaca_eval/ ）。\n",
    "- 在下一节中，我们将采用类似于AlpacaEval的方法，使用另一个LLM来评估我们的模型响应；不过，我们将使用自己的测试集，而不是公开可用的基准数据集。\n",
    "- 为此，我们将模型响应添加到test_data字典中，并将其保存为“instruction-data-with-response.json”文件进行记录，以便在需要时加载并在单独的Python会话中进行分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ca2cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [02:34<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ed5d7",
   "metadata": {},
   "source": [
    "- 让我们重新检查其中一条条目，查看响应是否已正确添加到test_data字典中。最后，我们还将保存模型，以防我们将来需要重用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "faf7d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11fc7beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60440e2",
   "metadata": {},
   "source": [
    "## 7.8 评估微调的LLM\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-7.webp?1\" width=500px>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f81e7",
   "metadata": {},
   "source": [
    "- 在本节中，我们使用另一个更大的LLM自动化评估微调后的LLM响应。\n",
    "- 特别地，我们使用Meta AI的一个微调指令的8亿参数Llama 3模型，它可以通过ollama（https://ollama.com ）本地运行。 （如果您更喜欢使用像GPT-4这样的更强大的LLM通过OpenAI API，请参见llm-instruction-eval-openai.ipynb笔记本）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4054b2ad",
   "metadata": {},
   "source": [
    "- Ollama是一个高效运行LLM的应用程序，它是一个封装在llama.cpp（https://github.com/ggerganov/llama.cpp ）中的工具，后者实现了用纯C/C++编写的LLM，以最大化效率。\n",
    "- 需要注意的是，它是一个用于生成文本（推理）的LLM工具，而不是用于训练或微调LLM。\n",
    "\n",
    "- 在运行下面的代码之前，请访问https://ollama.com 并按照说明安装ollama（例如，点击“下载”按钮并下载适合您的操作系统的ollama应用程序）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6188db",
   "metadata": {},
   "source": [
    "- 对于macOS和Windows用户，点击下载的ollama应用程序；如果它提示您安装命令行使用，请选择“是”。\n",
    "- Linux用户可以使用ollama网站上提供的安装命令。\n",
    "\n",
    "- 通常，在我们可以从命令行使用ollama之前，必须启动ollama应用程序或在另一个终端中运行ollama serve。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ollama-run.webp?1\" width=700px>\n",
    "\n",
    "- 在另一个终端中运行ollama应用程序或ollama serve后，在命令行中执行以下命令来尝试运行8亿参数的Llama 3模型（该模型占用4.7 GB存储空间，首次执行此命令时会自动下载）。\n",
    "\n",
    "\n",
    "```bash\n",
    "# 8B model\n",
    "ollama run llama3\n",
    "```\n",
    "\n",
    "\n",
    "The output looks like as follows\n",
    "\n",
    "```\n",
    "$ ollama run llama3\n",
    "pulling manifest\n",
    "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
    "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB\n",
    "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B\n",
    "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B\n",
    "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "removing any unused layers\n",
    "success\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- 需要注意的是，llama3指的是微调过的8亿参数Llama 3模型。\n",
    "\n",
    "- 使用“llama3”模型（一个8B参数模型）需要16 GB的RAM；如果您的机器不支持此要求，您可以尝试较小的模型，例如3.8B参数的phi-3模型，只需要8 GB的RAM， `model = \"phi-3\"`。\n",
    "\n",
    "- 另外，如果您的机器支持，您还可以使用更大的70亿参数Llama 3模型，将llama3替换为llama3:70b。\n",
    "\n",
    "- 下载完成后，您将看到一个命令行提示，允许您与模型聊天。\n",
    "- 尝试一个类似“Llamas吃什么？”的提示，应该会返回类似以下的输出。您可以通过输入/bye结束此会话。\n",
    "\n",
    "\n",
    "```\n",
    ">>> What do llamas eat?\n",
    "Llamas are ruminant animals, which means they have a four-chambered\n",
    "stomach and eat plants that are high in fiber. In the wild, llamas\n",
    "typically feed on:\n",
    "1. Grasses: They love to graze on various types of grasses, including tall\n",
    "grasses, wheat, oats, and barley.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1557b9",
   "metadata": {},
   "source": [
    "- 可以用input  `/bye` 来结束这个session\n",
    "- 以下代码会在继续使用ollama评估我们在上一节生成的测试集响应之前，检查ollama会话是否正常运行。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5fed45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31ec4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is optional; it allows you to restart the notebook\n",
    "# and only run section 7.7 without rerunning any of the previous code\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469224da",
   "metadata": {},
   "source": [
    "- 现在，除了之前用于与模型交互的ollama run命令，您还可以通过其REST API在Python中使用以下函数与模型交互。\n",
    "\n",
    "- 在运行本笔记本中的下一个单元格之前，请确保ollama仍在运行（前面的代码单元格应该打印出“Ollama running: True”）。\n",
    "\n",
    "- 接下来，运行以下代码单元格以查询模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85ebbb82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and digestive system.\n",
      "\n",
      "In the wild, llamas would typically roam in herds, grazing on whatever plants are available in their natural habitat. In captivity, llama owners should provide a balanced diet that meets their animal's nutritional needs.\n",
      "\n",
      "Some interesting facts about llama eating habits:\n",
      "\n",
      "* Llamas have a unique way of eating: they use their tongue to pluck grasses and other plants, then swallow the plant material whole.\n",
      "* They can eat up to 10-15% of their body weight in dry matter daily. For example, a 400-pound llama might consume around 40-60 pounds of food per day!\n",
      "* Llamas are known for their ability to survive on poor-quality forage, making them well-suited to areas with limited vegetation.\n",
      "\n",
      "Remember to consult with a veterinarian or experienced llama breeder to determine the best diet for your specific llama.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3\",\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a79c3df",
   "metadata": {},
   "source": [
    "- 通过我们定义的query_model函数，我们可以评估微调后的模型的响应；让我们在之前查看过的前三个测试集响应上试一试。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c99a6a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Score:\n",
      ">> I'd rate the model response \"The car is as fast as a bullet.\" an 85 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response uses a simile correctly, comparing the speed of the car to something else (in this case, a bullet).\n",
      "* The comparison is relevant and makes sense, as bullets are known for their high velocity.\n",
      "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
      "\n",
      "The only reason I wouldn't give it a perfect score is that some people might not immediately think of bullets when they hear \"fast\", whereas lightning is often an intuitive comparison for speed. However, \"as fast as a bullet\" is still a strong and effective simile that effectively conveys the idea that the car is very quick!\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Score:\n",
      ">> I'd score this model response as 40 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The model correctly identifies that thunderstorms are related to clouds (correctly identifying the type of phenomenon).\n",
      "* However, it incorrectly specifies the type of cloud associated with thunderstorms. Cumulus clouds are not typically associated with thunderstorms; cumulonimbus clouds are.\n",
      "* The response also lacks precision and clarity, using a vague phrase (\"The type of cloud associated with thunderstorms\") instead of a specific and accurate description.\n",
      "\n",
      "Overall, while the model attempts to address the instruction, it provides an incorrect answer that doesn't accurately complete the request.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> I'd rate my own response as 95 out of 100. Here's why:\n",
      "\n",
      "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
      "* The response is concise and clear, making it easy to understand.\n",
      "* There are no grammatical errors or inaccuracies in the response.\n",
      "\n",
      "The only reason I wouldn't give myself a perfect score is that the response is slightly redundant - it's not necessary to say \"The author of 'Pride and Prejudice' is\" since the question already asks for the author. However, this is a minor quibble, and overall, my response is well-written and accurate.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e4e23",
   "metadata": {},
   "source": [
    "- 正如我们所看到的，Llama 3模型提供了合理的评估，如果模型没有完全正确，它也会给出部分分数，正如我们在“积云”答案中看到的那样。\n",
    "\n",
    "- 需要注意的是，之前的提示返回了非常冗长的评估verbose evaluations；我们可以调整提示生成一个介于0到100之间的整数响应（其中100是最佳），以便计算模型的平均分数。\n",
    "\n",
    "- 在M3 MacBook Air笔记本上，评估测试集中的110个条目大约需要1分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f697e822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|███████████████████████████████████████████████████████████████| 110/110 [04:15<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 48.73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e52363",
   "metadata": {},
   "source": [
    "\n",
    "- 我们的模型平均得分超过50，这可以作为参考点，用来将模型与其他模型进行比较，或者尝试其他训练设置，看看是否能提高模型表现。\n",
    "\n",
    "- 需要注意的是，ollama在不同操作系统上的表现并非完全确定（截至本编写时），因此您得到的分数可能会与上述显示的略有不同。\n",
    "\n",
    "- 作为参考，原始的Llama 3 8B基础模型得分为58.51，Llama 3 8B指令模型得分为82.65。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506578a",
   "metadata": {},
   "source": [
    "## 7.9 总结\n",
    "### 7.9.1 接下来是什么\n",
    "- 这是本书的最后一章。\n",
    "- 我们已经覆盖了 LLM 开发周期中的主要步骤：实现一个 LLM 的架构、预训练 LLM，以及对其进行微调。\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/final-overview.webp?1\" width=500px>\n",
    "- 在本章描述的指令微调之后，有时还会进行一个可选步骤：偏好微调（preference finetuning）。\n",
    "\n",
    "- 偏好微调的过程对定制模型以更好地符合特定用户偏好非常有用。如果对此感兴趣，可以参考 GitHub 仓库中 ../04_preference-tuning-with-dpo 文件夹中的内容。\n",
    "\n",
    "- 此外，本仓库还包含大量额外的补充材料，可能会让您感兴趣。有关更多信息，请参阅此仓库的 README 页面中的 Bonus Material 部分。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b806d4",
   "metadata": {},
   "source": [
    "## 7.9.2 在快速发展的领域中保持更新\n",
    "这一节没有代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba9bb0b",
   "metadata": {},
   "source": [
    "### 7.9.3 最后的话\n",
    "希望您享受了从零实现一个 LLM 的旅程，并亲手编写了预训练和微调函数。\n",
    "\n",
    "在我看来，从头实现一个 LLM 是理解其工作原理的最佳方式；我希望通过这种方法，您对 LLM 有了更深入的理解。\n",
    "\n",
    "尽管本书以教育为目的，但您可能对在实际应用中使用不同的、更强大的 LLM 感兴趣。\n",
    "\n",
    "为此，您可以考虑一些流行工具，例如 axolotl 或 LitGPT，这些工具的开发我也参与了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592112bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
